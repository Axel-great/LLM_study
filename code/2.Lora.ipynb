{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lora微调的线性实现方式\n",
    "lora微调有两种东西要更新\n",
    "1. X自身的值\n",
    "2. W权重\n",
    "\n",
    "$$\n",
    "Y = WX + X \\cdot (A B)\n",
    "$$\n",
    "\n",
    "需要判断X和W是否更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为什么要用nn.Parameters?\n",
    "因为AB矩阵的weight值需要被反向传播而更新，用nn.rand的值默认不会被反向传播更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 576])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class LinearLoralayer(nn.Module):\n",
    "    def __init__(self, \n",
    "    in_features,\n",
    "    out_features,\n",
    "    rank,\n",
    "    alpha,\n",
    "    drop_out,\n",
    "    merge=False):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self.merge = merge\n",
    "        self.linear = nn.Linear(in_features,out_features)\n",
    "\n",
    "        # 生成一个rank 用于模拟输入的数据\n",
    "        # W的维度默认为(out_features , in_features) 因为 y=X*W^T\n",
    "        # 不能对这部分的参数进行反向传播\n",
    "        if drop_out > 0:\n",
    "            self.drop_out = nn.Dropout(drop_out)\n",
    "        else:\n",
    "            # indentity不做变化\n",
    "            self.drop_out = nn.Identity()\n",
    "\n",
    "        if rank > 0 :\n",
    "            self.lora_a = nn.Parameter(torch.zeros(out_features,rank))\n",
    "            # lora_a 需要初始化为 高斯分布\n",
    "            # @春风归无期 提醒我 @用代码打点酱油的chaofa : 在调用凯明初始化的时候注释里写的高斯分布，调用的却是均匀分布，而且参数a的值设置的是根号5，但a表示的是leaky relu的负斜率系数，一般是0.01这样的小值，不可能超过1\n",
    "            nn.init.kaiming_normal_(self.lora_a, a=0.01)\n",
    "\n",
    "            self.lora_b = nn.Parameter(torch.zeros(rank,in_features))\n",
    "            self.scale = rank / alpha\n",
    "            self.linear.weight.requires_grad = False\n",
    "\n",
    "\n",
    "        if merge:\n",
    "            self.merge_weight()\n",
    "    \n",
    "    def merge_weight(self):\n",
    "        if self.merge and self.rank >0 :\n",
    "            # 需要合并W权重\n",
    "            # 这里不需要转置是因为W的矩阵就是(out_features,in_features)\n",
    "            self.linear.weight.data += self.scale * (self.lora_a @ self.lora_b)\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "        if rank > 0 :\n",
    "            # lora_a * lora_b (out_features * in_features)\n",
    "            # X dimension is (batch,in_features)\n",
    "            # y = Wx + x*AB\n",
    "            output1 = self.linear(X)\n",
    "            output2 = self.scale * (X @ (self.lora_a @ self.lora_b).T)\n",
    "            output = output1 + output2\n",
    "        else:\n",
    "            # rank < 0 故不作lora,过一个线性层即可\n",
    "            output = self.linear(X)\n",
    "        output = self.drop_out(output)\n",
    "        return output\n",
    "\n",
    "batch_size = 128\n",
    "seq_len = 64\n",
    "\n",
    "out_features = 576\n",
    "in_features = 512\n",
    "dropout = 0.1\n",
    "rank = 16 #一般为4-32\n",
    "alpha = 32\n",
    "\n",
    "X = torch.rand(batch_size,seq_len,in_features)\n",
    "# torch.rand 创建的张量不会被更新\n",
    "model = LinearLoralayer(\n",
    "    in_features= in_features,\n",
    "    out_features= out_features,\n",
    "    drop_out=dropout,\n",
    "    rank=rank,\n",
    "    alpha=alpha,\n",
    "    merge=True\n",
    ")\n",
    "output = model(X)\n",
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
